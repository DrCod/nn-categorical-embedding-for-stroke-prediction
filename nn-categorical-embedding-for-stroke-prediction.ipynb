{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\n\n\nimport gc\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-06T14:49:41.223219Z","iopub.execute_input":"2023-02-06T14:49:41.223996Z","iopub.status.idle":"2023-02-06T14:49:47.210602Z","shell.execute_reply.started":"2023-02-06T14:49:41.223905Z","shell.execute_reply":"2023-02-06T14:49:47.209596Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"random.seed(2023)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:47.212360Z","iopub.execute_input":"2023-02-06T14:49:47.212926Z","iopub.status.idle":"2023-02-06T14:49:47.225380Z","shell.execute_reply.started":"2023-02-06T14:49:47.212897Z","shell.execute_reply":"2023-02-06T14:49:47.222830Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:47.227312Z","iopub.execute_input":"2023-02-06T14:49:47.227926Z","iopub.status.idle":"2023-02-06T14:49:47.277158Z","shell.execute_reply.started":"2023-02-06T14:49:47.227888Z","shell.execute_reply":"2023-02-06T14:49:47.276116Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:47.280890Z","iopub.execute_input":"2023-02-06T14:49:47.281601Z","iopub.status.idle":"2023-02-06T14:49:47.290178Z","shell.execute_reply.started":"2023-02-06T14:49:47.281563Z","shell.execute_reply":"2023-02-06T14:49:47.289081Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(5110, 12)"},"metadata":{}}]},{"cell_type":"code","source":"display(df.head())","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:47.292045Z","iopub.execute_input":"2023-02-06T14:49:47.292427Z","iopub.status.idle":"2023-02-06T14:49:47.316328Z","shell.execute_reply.started":"2023-02-06T14:49:47.292394Z","shell.execute_reply":"2023-02-06T14:49:47.315432Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"      id  gender   age  hypertension  heart_disease ever_married  \\\n0   9046    Male  67.0             0              1          Yes   \n1  51676  Female  61.0             0              0          Yes   \n2  31112    Male  80.0             0              1          Yes   \n3  60182  Female  49.0             0              0          Yes   \n4   1665  Female  79.0             1              0          Yes   \n\n       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n0        Private          Urban             228.69  36.6  formerly smoked   \n1  Self-employed          Rural             202.21   NaN     never smoked   \n2        Private          Rural             105.92  32.5     never smoked   \n3        Private          Urban             171.23  34.4           smokes   \n4  Self-employed          Rural             174.12  24.0     never smoked   \n\n   stroke  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n      <th>stroke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9046</td>\n      <td>Male</td>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>228.69</td>\n      <td>36.6</td>\n      <td>formerly smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>51676</td>\n      <td>Female</td>\n      <td>61.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>202.21</td>\n      <td>NaN</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31112</td>\n      <td>Male</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>105.92</td>\n      <td>32.5</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60182</td>\n      <td>Female</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>171.23</td>\n      <td>34.4</td>\n      <td>smokes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1665</td>\n      <td>Female</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>174.12</td>\n      <td>24.0</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.stroke.value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:47.319494Z","iopub.execute_input":"2023-02-06T14:49:47.319793Z","iopub.status.idle":"2023-02-06T14:49:47.540707Z","shell.execute_reply.started":"2023-02-06T14:49:47.319751Z","shell.execute_reply":"2023-02-06T14:49:47.540014Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:47.542217Z","iopub.execute_input":"2023-02-06T14:49:47.542610Z","iopub.status.idle":"2023-02-06T14:49:47.565048Z","shell.execute_reply.started":"2023-02-06T14:49:47.542573Z","shell.execute_reply":"2023-02-06T14:49:47.563987Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"id                     0\ngender                 0\nage                    0\nhypertension           0\nheart_disease          0\never_married           0\nwork_type              0\nResidence_type         0\navg_glucose_level      0\nbmi                  201\nsmoking_status         0\nstroke                 0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Impute missing values in BMI","metadata":{}},{"cell_type":"code","source":"# Here we use simple mean value to impute missing values in BMI\n\ndf['bmi'] = df['bmi'].fillna(df['bmi'].mean())","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:48.427270Z","iopub.execute_input":"2023-02-06T14:49:48.429604Z","iopub.status.idle":"2023-02-06T14:49:48.435641Z","shell.execute_reply.started":"2023-02-06T14:49:48.429559Z","shell.execute_reply":"2023-02-06T14:49:48.434584Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# extract categorical features\n\ncategorical_features = df.columns[df.dtypes == 'object'].tolist()\n\nprint(categorical_features)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:48.554741Z","iopub.execute_input":"2023-02-06T14:49:48.555094Z","iopub.status.idle":"2023-02-06T14:49:48.561538Z","shell.execute_reply.started":"2023-02-06T14:49:48.555062Z","shell.execute_reply":"2023-02-06T14:49:48.560384Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n","output_type":"stream"}]},{"cell_type":"code","source":"numerical_features = df.columns.difference(categorical_features + ['id', 'stroke']).tolist()\n\nprint(numerical_features)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:48.773798Z","iopub.execute_input":"2023-02-06T14:49:48.774162Z","iopub.status.idle":"2023-02-06T14:49:48.781587Z","shell.execute_reply.started":"2023-02-06T14:49:48.774131Z","shell.execute_reply":"2023-02-06T14:49:48.780363Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['age', 'avg_glucose_level', 'bmi', 'heart_disease', 'hypertension']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Preparation Pipeline","metadata":{}},{"cell_type":"code","source":"embedding_dims = {\n    \n    k : (df[k].nunique(), df[k].nunique() // 2)\n    \n    for k in categorical_features\n}\n\nembedding_dims","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:49.940965Z","iopub.execute_input":"2023-02-06T14:49:49.941840Z","iopub.status.idle":"2023-02-06T14:49:49.955855Z","shell.execute_reply.started":"2023-02-06T14:49:49.941806Z","shell.execute_reply":"2023-02-06T14:49:49.954619Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'gender': (3, 1),\n 'ever_married': (2, 1),\n 'work_type': (5, 2),\n 'Residence_type': (2, 1),\n 'smoking_status': (4, 2)}"},"metadata":{}}]},{"cell_type":"markdown","source":"*Feature Transformer*","metadata":{}},{"cell_type":"code","source":"#Convert data inot a multi-input list format to match the model architecture\ndef feature_transformer(train, test):\n\n    input_list_train = []\n    input_list_test = []\n    \n    # Extract all columns(categorical) to be fed into an embedding layer\n    for c in categorical_features:\n        # all unique categories in column `c`\n        raw_vals = np.unique(train[c])\n        val_map = {}\n        for i in range(len(raw_vals)):\n            # encode unique categories in column `c`\n            val_map[raw_vals[i]] = i       \n            \n        input_list_train.append(train[c].map(val_map).values)\n        input_list_test.append(test[c].map(val_map).values)\n     \n    # Extract remaining non-embedding columns - input of numeric the feedforward embedding layer\n    num_cols = [c for c in train.columns if (not c in categorical_features + ['id', 'stroke'])]\n    input_list_train.append(train[num_cols].values)\n    input_list_test.append(test[num_cols].values)\n    \n    \n    return input_list_train, input_list_test  ","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:50.958741Z","iopub.execute_input":"2023-02-06T14:49:50.959110Z","iopub.status.idle":"2023-02-06T14:49:50.967690Z","shell.execute_reply.started":"2023-02-06T14:49:50.959080Z","shell.execute_reply":"2023-02-06T14:49:50.966552Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Create Train/Test Split","metadata":{}},{"cell_type":"code","source":"df['stroke'] = df['stroke'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:52.024819Z","iopub.execute_input":"2023-02-06T14:49:52.025177Z","iopub.status.idle":"2023-02-06T14:49:52.030795Z","shell.execute_reply.started":"2023-02-06T14:49:52.025147Z","shell.execute_reply":"2023-02-06T14:49:52.029495Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# We will first create train/test splits\n\ndf_train, df_test, y_train, y_test = train_test_split(df, df['stroke'], test_size =0.2, stratify=df['stroke'], shuffle=True, random_state =2023)\n\n\nprint(f'(train X , train y): {df_train.shape, y_train.shape}, (test X, test y) : {df_test.shape, y_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:52.237452Z","iopub.execute_input":"2023-02-06T14:49:52.239619Z","iopub.status.idle":"2023-02-06T14:49:52.254035Z","shell.execute_reply.started":"2023-02-06T14:49:52.239570Z","shell.execute_reply":"2023-02-06T14:49:52.252466Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(train X , train y): ((4088, 12), (4088,)), (test X, test y) : ((1022, 12), (1022,))\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:52.398171Z","iopub.execute_input":"2023-02-06T14:49:52.399198Z","iopub.status.idle":"2023-02-06T14:49:52.617692Z","shell.execute_reply.started":"2023-02-06T14:49:52.399155Z","shell.execute_reply":"2023-02-06T14:49:52.616587Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"88"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_model(num_numeric_cols):\n\n    act_fn = 'relu'\n    \n    dr = 0.2\n    \n    lr = 0.001\n\n    inputs = []\n    embeddings = []\n\n\n    for i in embedding_dims.keys():\n\n        input = tf.keras.layers.Input(shape=(1), dtype = tf.int32)\n\n        x, y = embedding_dims[i]\n\n        emb = tf.keras.layers.Embedding(x, y,  input_length = 1)(input)\n\n        emb = tf.keras.layers.Reshape(target_shape=(y,))(emb)\n\n        inputs.append(input)\n        embeddings.append(emb)\n\n\n    inp = tf.keras.Input(shape=(num_numeric_cols, ), name =\"numeric_features\", dtype = tf.float32)   \n    num_emb = tf.keras.layers.Dense(256, activation = act_fn)(inp)\n\n    inputs.append(inp)\n    embeddings.append(num_emb)\n\n    x = tf.keras.layers.Concatenate()(embeddings)\n\n    x = tf.keras.layers.Dense( 128, activation = act_fn)(x)  \n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(rate=dr)(x)   \n\n    x = tf.keras.layers.Dense( 128, activation = act_fn)(x)  \n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(rate=dr)(x) \n    \n\n    preds = tf.keras.layers.Dense(1,activation = 'sigmoid' , name =\"classifier\")(x)\n\n    model = tf.keras.models.Model(inputs = inputs ,outputs = preds )\n    \n  \n    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n\n    model.compile(loss= \"binary_crossentropy\",\n                optimizer= opt,\n                metrics = ['Accuracy']\n                )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:51:50.801054Z","iopub.execute_input":"2023-02-06T14:51:50.801456Z","iopub.status.idle":"2023-02-06T14:51:50.817469Z","shell.execute_reply.started":"2023-02-06T14:51:50.801425Z","shell.execute_reply":"2023-02-06T14:51:50.816405Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"X_train, X_test = feature_transformer( train = df_train, test = df_test  )\n\nY_train , Y_test = y_train.values, y_test.values","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:49:53.853236Z","iopub.execute_input":"2023-02-06T14:49:53.853848Z","iopub.status.idle":"2023-02-06T14:49:53.877160Z","shell.execute_reply.started":"2023-02-06T14:49:53.853790Z","shell.execute_reply":"2023-02-06T14:49:53.876213Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 100\n\nn_num_cols = len(numerical_features)\n\nes = tf.keras.callbacks.EarlyStopping(patience=50, mode='min', verbose=1, monitor = \"val_loss\", min_delta = 0.00001, restore_best_weights=True) \n\n# init model\nmodel = get_model(num_numeric_cols = n_num_cols)\n\nmodel.fit(\n        X_train, Y_train,\n        validation_data = (X_test, Y_test),\n        batch_size = batch_size,\n        epochs = epochs,\n        callbacks = [es],\n        )","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:51:58.070687Z","iopub.execute_input":"2023-02-06T14:51:58.071141Z","iopub.status.idle":"2023-02-06T14:53:37.323253Z","shell.execute_reply.started":"2023-02-06T14:51:58.071103Z","shell.execute_reply":"2023-02-06T14:53:37.322344Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/100\n128/128 [==============================] - 3s 9ms/step - loss: 0.5026 - Accuracy: 0.7921 - val_loss: 0.4618 - val_Accuracy: 0.8268\nEpoch 2/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.2476 - Accuracy: 0.9325 - val_loss: 0.1662 - val_Accuracy: 0.9511\nEpoch 3/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.2021 - Accuracy: 0.9408 - val_loss: 0.1742 - val_Accuracy: 0.9511\nEpoch 4/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1833 - Accuracy: 0.9447 - val_loss: 0.1589 - val_Accuracy: 0.9511\nEpoch 5/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1918 - Accuracy: 0.9437 - val_loss: 0.1688 - val_Accuracy: 0.9442\nEpoch 6/100\n128/128 [==============================] - 1s 9ms/step - loss: 0.1836 - Accuracy: 0.9447 - val_loss: 0.1585 - val_Accuracy: 0.9511\nEpoch 7/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1817 - Accuracy: 0.9467 - val_loss: 0.2370 - val_Accuracy: 0.9511\nEpoch 8/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1818 - Accuracy: 0.9472 - val_loss: 0.1606 - val_Accuracy: 0.9511\nEpoch 9/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1753 - Accuracy: 0.9491 - val_loss: 0.1665 - val_Accuracy: 0.9462\nEpoch 10/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1735 - Accuracy: 0.9486 - val_loss: 0.1575 - val_Accuracy: 0.9511\nEpoch 11/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1732 - Accuracy: 0.9464 - val_loss: 0.1558 - val_Accuracy: 0.9511\nEpoch 12/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1765 - Accuracy: 0.9469 - val_loss: 0.1541 - val_Accuracy: 0.9511\nEpoch 13/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1700 - Accuracy: 0.9489 - val_loss: 0.1601 - val_Accuracy: 0.9511\nEpoch 14/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1730 - Accuracy: 0.9484 - val_loss: 0.1552 - val_Accuracy: 0.9511\nEpoch 15/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1720 - Accuracy: 0.9494 - val_loss: 0.1546 - val_Accuracy: 0.9511\nEpoch 16/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1721 - Accuracy: 0.9477 - val_loss: 0.1553 - val_Accuracy: 0.9511\nEpoch 17/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1707 - Accuracy: 0.9489 - val_loss: 0.1534 - val_Accuracy: 0.9511\nEpoch 18/100\n128/128 [==============================] - 1s 9ms/step - loss: 0.1725 - Accuracy: 0.9481 - val_loss: 0.1577 - val_Accuracy: 0.9511\nEpoch 19/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1661 - Accuracy: 0.9503 - val_loss: 0.1594 - val_Accuracy: 0.9511\nEpoch 20/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1698 - Accuracy: 0.9486 - val_loss: 0.1549 - val_Accuracy: 0.9511\nEpoch 21/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1634 - Accuracy: 0.9501 - val_loss: 0.1760 - val_Accuracy: 0.9511\nEpoch 22/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1659 - Accuracy: 0.9511 - val_loss: 0.1816 - val_Accuracy: 0.9335\nEpoch 23/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1673 - Accuracy: 0.9513 - val_loss: 0.1543 - val_Accuracy: 0.9511\nEpoch 24/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1655 - Accuracy: 0.9501 - val_loss: 0.1520 - val_Accuracy: 0.9511\nEpoch 25/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1626 - Accuracy: 0.9506 - val_loss: 0.1542 - val_Accuracy: 0.9511\nEpoch 26/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1657 - Accuracy: 0.9501 - val_loss: 0.1564 - val_Accuracy: 0.9511\nEpoch 27/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1631 - Accuracy: 0.9511 - val_loss: 0.1543 - val_Accuracy: 0.9511\nEpoch 28/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1677 - Accuracy: 0.9494 - val_loss: 0.1537 - val_Accuracy: 0.9511\nEpoch 29/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1631 - Accuracy: 0.9499 - val_loss: 0.1614 - val_Accuracy: 0.9511\nEpoch 30/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1675 - Accuracy: 0.9513 - val_loss: 0.1541 - val_Accuracy: 0.9511\nEpoch 31/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1638 - Accuracy: 0.9491 - val_loss: 0.1663 - val_Accuracy: 0.9511\nEpoch 32/100\n128/128 [==============================] - 1s 11ms/step - loss: 0.1666 - Accuracy: 0.9513 - val_loss: 0.1523 - val_Accuracy: 0.9511\nEpoch 33/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1639 - Accuracy: 0.9501 - val_loss: 0.1549 - val_Accuracy: 0.9511\nEpoch 34/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1620 - Accuracy: 0.9503 - val_loss: 0.1545 - val_Accuracy: 0.9511\nEpoch 35/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1671 - Accuracy: 0.9508 - val_loss: 0.1549 - val_Accuracy: 0.9511\nEpoch 36/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1653 - Accuracy: 0.9499 - val_loss: 0.1532 - val_Accuracy: 0.9511\nEpoch 37/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1641 - Accuracy: 0.9503 - val_loss: 0.1582 - val_Accuracy: 0.9511\nEpoch 38/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1661 - Accuracy: 0.9506 - val_loss: 0.1577 - val_Accuracy: 0.9511\nEpoch 39/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1672 - Accuracy: 0.9506 - val_loss: 0.1652 - val_Accuracy: 0.9511\nEpoch 40/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1638 - Accuracy: 0.9508 - val_loss: 0.1554 - val_Accuracy: 0.9511\nEpoch 41/100\n128/128 [==============================] - 1s 9ms/step - loss: 0.1601 - Accuracy: 0.9503 - val_loss: 0.1574 - val_Accuracy: 0.9511\nEpoch 42/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1636 - Accuracy: 0.9508 - val_loss: 0.1614 - val_Accuracy: 0.9511\nEpoch 43/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1643 - Accuracy: 0.9506 - val_loss: 0.1570 - val_Accuracy: 0.9511\nEpoch 44/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1623 - Accuracy: 0.9511 - val_loss: 0.1572 - val_Accuracy: 0.9511\nEpoch 45/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1592 - Accuracy: 0.9511 - val_loss: 0.1556 - val_Accuracy: 0.9511\nEpoch 46/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1638 - Accuracy: 0.9501 - val_loss: 0.1573 - val_Accuracy: 0.9511\nEpoch 47/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1627 - Accuracy: 0.9508 - val_loss: 0.1714 - val_Accuracy: 0.9511\nEpoch 48/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1601 - Accuracy: 0.9516 - val_loss: 0.1560 - val_Accuracy: 0.9511\nEpoch 49/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1619 - Accuracy: 0.9508 - val_loss: 0.1532 - val_Accuracy: 0.9511\nEpoch 50/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1582 - Accuracy: 0.9511 - val_loss: 0.1527 - val_Accuracy: 0.9511\nEpoch 51/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1632 - Accuracy: 0.9503 - val_loss: 0.1834 - val_Accuracy: 0.9511\nEpoch 52/100\n128/128 [==============================] - 1s 9ms/step - loss: 0.1623 - Accuracy: 0.9499 - val_loss: 0.1597 - val_Accuracy: 0.9501\nEpoch 53/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1628 - Accuracy: 0.9506 - val_loss: 0.1585 - val_Accuracy: 0.9511\nEpoch 54/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1606 - Accuracy: 0.9511 - val_loss: 0.1520 - val_Accuracy: 0.9511\nEpoch 55/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1612 - Accuracy: 0.9513 - val_loss: 0.1541 - val_Accuracy: 0.9511\nEpoch 56/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1601 - Accuracy: 0.9508 - val_loss: 0.1563 - val_Accuracy: 0.9511\nEpoch 57/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1616 - Accuracy: 0.9513 - val_loss: 0.1542 - val_Accuracy: 0.9511\nEpoch 58/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1586 - Accuracy: 0.9513 - val_loss: 0.1559 - val_Accuracy: 0.9511\nEpoch 59/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1599 - Accuracy: 0.9511 - val_loss: 0.1517 - val_Accuracy: 0.9511\nEpoch 60/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1631 - Accuracy: 0.9508 - val_loss: 0.1645 - val_Accuracy: 0.9511\nEpoch 61/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1625 - Accuracy: 0.9511 - val_loss: 0.1537 - val_Accuracy: 0.9511\nEpoch 62/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1635 - Accuracy: 0.9511 - val_loss: 0.1544 - val_Accuracy: 0.9511\nEpoch 63/100\n128/128 [==============================] - 1s 9ms/step - loss: 0.1615 - Accuracy: 0.9513 - val_loss: 0.1538 - val_Accuracy: 0.9511\nEpoch 64/100\n128/128 [==============================] - 1s 11ms/step - loss: 0.1600 - Accuracy: 0.9503 - val_loss: 0.1540 - val_Accuracy: 0.9511\nEpoch 65/100\n128/128 [==============================] - 1s 9ms/step - loss: 0.1594 - Accuracy: 0.9513 - val_loss: 0.1570 - val_Accuracy: 0.9511\nEpoch 66/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1599 - Accuracy: 0.9508 - val_loss: 0.1601 - val_Accuracy: 0.9511\nEpoch 67/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1617 - Accuracy: 0.9511 - val_loss: 0.1541 - val_Accuracy: 0.9511\nEpoch 68/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1607 - Accuracy: 0.9513 - val_loss: 0.1535 - val_Accuracy: 0.9511\nEpoch 69/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1598 - Accuracy: 0.9513 - val_loss: 0.1546 - val_Accuracy: 0.9511\nEpoch 70/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1595 - Accuracy: 0.9511 - val_loss: 0.1550 - val_Accuracy: 0.9511\nEpoch 71/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1606 - Accuracy: 0.9508 - val_loss: 0.1526 - val_Accuracy: 0.9511\nEpoch 72/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1582 - Accuracy: 0.9511 - val_loss: 0.1537 - val_Accuracy: 0.9511\nEpoch 73/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1607 - Accuracy: 0.9513 - val_loss: 0.1562 - val_Accuracy: 0.9511\nEpoch 74/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1613 - Accuracy: 0.9513 - val_loss: 0.1611 - val_Accuracy: 0.9511\nEpoch 75/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1583 - Accuracy: 0.9511 - val_loss: 0.1512 - val_Accuracy: 0.9511\nEpoch 76/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1615 - Accuracy: 0.9513 - val_loss: 0.1536 - val_Accuracy: 0.9511\nEpoch 77/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1572 - Accuracy: 0.9511 - val_loss: 0.1546 - val_Accuracy: 0.9511\nEpoch 78/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1588 - Accuracy: 0.9511 - val_loss: 0.1512 - val_Accuracy: 0.9511\nEpoch 79/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1587 - Accuracy: 0.9516 - val_loss: 0.1609 - val_Accuracy: 0.9511\nEpoch 80/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1583 - Accuracy: 0.9513 - val_loss: 0.1562 - val_Accuracy: 0.9511\nEpoch 81/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1580 - Accuracy: 0.9516 - val_loss: 0.1550 - val_Accuracy: 0.9511\nEpoch 82/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1598 - Accuracy: 0.9513 - val_loss: 0.1538 - val_Accuracy: 0.9511\nEpoch 83/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1613 - Accuracy: 0.9513 - val_loss: 0.1551 - val_Accuracy: 0.9511\nEpoch 84/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1579 - Accuracy: 0.9513 - val_loss: 0.1569 - val_Accuracy: 0.9511\nEpoch 85/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1574 - Accuracy: 0.9513 - val_loss: 0.1502 - val_Accuracy: 0.9511\nEpoch 86/100\n128/128 [==============================] - 1s 9ms/step - loss: 0.1582 - Accuracy: 0.9511 - val_loss: 0.1557 - val_Accuracy: 0.9511\nEpoch 87/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1576 - Accuracy: 0.9511 - val_loss: 0.1805 - val_Accuracy: 0.9511\nEpoch 88/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1581 - Accuracy: 0.9511 - val_loss: 0.1534 - val_Accuracy: 0.9511\nEpoch 89/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1593 - Accuracy: 0.9513 - val_loss: 0.1529 - val_Accuracy: 0.9511\nEpoch 90/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1593 - Accuracy: 0.9513 - val_loss: 0.1557 - val_Accuracy: 0.9511\nEpoch 91/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1556 - Accuracy: 0.9513 - val_loss: 0.1528 - val_Accuracy: 0.9511\nEpoch 92/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1583 - Accuracy: 0.9513 - val_loss: 0.1517 - val_Accuracy: 0.9511\nEpoch 93/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1604 - Accuracy: 0.9513 - val_loss: 0.1651 - val_Accuracy: 0.9511\nEpoch 94/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1607 - Accuracy: 0.9513 - val_loss: 0.1532 - val_Accuracy: 0.9511\nEpoch 95/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1600 - Accuracy: 0.9511 - val_loss: 0.1571 - val_Accuracy: 0.9511\nEpoch 96/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1570 - Accuracy: 0.9513 - val_loss: 0.1655 - val_Accuracy: 0.9521\nEpoch 97/100\n128/128 [==============================] - 2s 14ms/step - loss: 0.1603 - Accuracy: 0.9513 - val_loss: 0.1551 - val_Accuracy: 0.9511\nEpoch 98/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1597 - Accuracy: 0.9513 - val_loss: 0.1539 - val_Accuracy: 0.9511\nEpoch 99/100\n128/128 [==============================] - 1s 7ms/step - loss: 0.1571 - Accuracy: 0.9513 - val_loss: 0.1586 - val_Accuracy: 0.9511\nEpoch 100/100\n128/128 [==============================] - 1s 8ms/step - loss: 0.1590 - Accuracy: 0.9516 - val_loss: 0.1547 - val_Accuracy: 0.9511\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f5adc7e2350>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred = model.predict(X_test)\n\ny_pred  = (y_pred > 0.5).astype(int)\n\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:55:27.933683Z","iopub.execute_input":"2023-02-06T14:55:27.934058Z","iopub.status.idle":"2023-02-06T14:55:28.057177Z","shell.execute_reply.started":"2023-02-06T14:55:27.934026Z","shell.execute_reply":"2023-02-06T14:55:28.056203Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([[0],\n       [0],\n       [0],\n       ...,\n       [0],\n       [0],\n       [0]])"},"metadata":{}}]},{"cell_type":"code","source":"print('Accuracy:', accuracy_score(Y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:55:33.453850Z","iopub.execute_input":"2023-02-06T14:55:33.454835Z","iopub.status.idle":"2023-02-06T14:55:33.462652Z","shell.execute_reply.started":"2023-02-06T14:55:33.454796Z","shell.execute_reply":"2023-02-06T14:55:33.461636Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Accuracy: 0.9510763209393346\n","output_type":"stream"}]}]}